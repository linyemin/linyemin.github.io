<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="cuda," />










<meta name="description" content="资料">
<meta name="keywords" content="cuda">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA简介">
<meta property="og:url" content="http://yoursite.com/2017/10/25/cuda-ppt/index.html">
<meta property="og:site_name" content="林烨敏的博客">
<meta property="og:description" content="资料">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/cuda-cpu-gpu-1.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/cuda-cpu-gpu-2.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/04795d344f33b2a88945624f9428b27e.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/3b73373d63529ff8b36e10ccb8141b00.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/a97718b65efee4716903ba08446b2317.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/6f4edcb49f25d819d49ea0b025bfd3c2.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/4271bf457dd3942214ababb5020046bf.png">
<meta property="og:image" content="http://outz1n6zr.bkt.clouddn.com/04795d344f33b2a88945624f9428b27e.png">
<meta property="og:updated_time" content="2017-11-30T12:01:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CUDA简介">
<meta name="twitter:description" content="资料">
<meta name="twitter:image" content="http://outz1n6zr.bkt.clouddn.com/cuda-cpu-gpu-1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/10/25/cuda-ppt/"/>





  <title>CUDA简介 | 林烨敏的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">林烨敏的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/25/cuda-ppt/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="linyemin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="林烨敏的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CUDA简介</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-25T10:30:00+08:00">
                2017-10-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/gpu/" itemprop="url" rel="index">
                    <span itemprop="name">gpu</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><a id="more"></a>
<h2 id="CPU与GPU"><a href="#CPU与GPU" class="headerlink" title="CPU与GPU"></a>CPU与GPU</h2><p>CPU（中央处理器）和GPU（图形处理器）由于其设计目标的不同，它们分别针对了两种不同的应用场景。</p>
<p>CPU需要很强的通用性来处理各种不同的数据类型，同时引入大量的分支跳转和中断来处理逻辑判断。这些使得CPU的内部结构异常复杂。</p>
<p>GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。</p>
<p><img src="http://outz1n6zr.bkt.clouddn.com/cuda-cpu-gpu-1.png" alt="CPU与GPU-1"></p>
<p>上图中，绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元。GPU采用了数量众多的计算单元和超长的流水线，但只有非常简单的控制逻辑并省去了Cache。而CPU不仅被Cache占据了大量空间，而且还有复杂的控制逻辑和诸多优化电路，相比之下计算能力只是CPU很小的一部分。cu</p>
<p><img src="http://outz1n6zr.bkt.clouddn.com/cuda-cpu-gpu-2.png" alt="CPU与GPU-2"></p>
<table>
<thead>
<tr>
<th>.</th>
<th>缓存、内存</th>
<th>线程</th>
<th>寄存器</th>
<th>SIMD单元</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>多</td>
<td>少</td>
<td>少</td>
<td>少</td>
</tr>
<tr>
<td>GPU</td>
<td>少</td>
<td>多</td>
<td>多</td>
<td>多</td>
</tr>
</tbody>
</table>
<blockquote>
<p>SIMD Unit(单指令多数据流,以同步方式，在同一时间内执行同一条指令)</p>
</blockquote>
<h3 id="CPU的设计理念——低延时"><a href="#CPU的设计理念——低延时" class="headerlink" title="CPU的设计理念——低延时"></a>CPU的设计理念——低延时</h3><ul>
<li>通过加强算术运算单元ALU来降低延时<ul>
<li>可以在很少的时钟周期内完成算术运算，执行双精度浮点运算也只需1 ~ 3个时钟周期。</li>
<li>Intel Core i7-7700K的主频高达4.2GHz。</li>
</ul>
</li>
<li>通过增大缓存来降低延时<ul>
<li>增大缓存从而提升缓存命中率。  </li>
</ul>
</li>
<li>复杂的逻辑控制单元<ul>
<li>分支预测降低分支延时,<a href="http://www.cnblogs.com/yangecnu/p/introduce-branch-predict-pipelining-and-conditonal-move-instruction.html" target="_blank" rel="noopener">参考</a><ul>
<li>当CPU遇到分支处理指令时(if-else)，无需等待判断结果，而由CPU自行决定执行哪个分支。当分支选择错误时，则放弃该分支，重新执行。</li>
<li>常用的分支预测方法包括静态分支预测法和动态分支预测法。</li>
<li>静态分支预测。任选一条分支，这样平均命中率为50%。更精确的办法是根据原先运行的结果进行统计从而尝试预测分支是否会跳转。</li>
<li>动态分支预测。最简单的动态分支预测策略是分支预测缓冲区（Branch Prediction Buff)或分支历史表(branch history table)。</li>
</ul>
</li>
<li>通过数据转发降低数据延时<ul>
<li>当一些指令依赖前面的指令结果时，数据转发的逻辑控制单元决定这些指令在pipeline中的位置并且尽可能快的转发一个指令的结果给后续的指令。这些动作需要很多的对比电路单元和转发电路单元。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="GPU的设计理念——大吞吐量"><a href="#GPU的设计理念——大吞吐量" class="headerlink" title="GPU的设计理念——大吞吐量"></a>GPU的设计理念——大吞吐量</h3><ul>
<li>小而少的缓存<ul>
<li>设计缓存的目的不是为了保存后面需要访问的数据(CPU)，而是为thread提供服务的。</li>
<li>当很多threads需要访问同一个数据时，缓存会合并这些访问，然后去访问dram(数据存放地)。</li>
<li>当缓存获取到数据后，会转发这个数据到对应的线程，这个时候是数据转发的角色。</li>
<li>由于需要访问dram，所以带来了延时问题。</li>
</ul>
</li>
<li>简单的控制单元<ul>
<li>配合缓存将多个访问合并成少的访问</li>
<li>没有分支预测、数据转发</li>
</ul>
</li>
<li>非常多的ALU</li>
<li>非常多的thread</li>
<li>通过大量线程的并行去忽略访问存储器的延时</li>
</ul>
<h3 id="形象的比喻"><a href="#形象的比喻" class="headerlink" title="形象的比喻"></a>形象的比喻</h3><ul>
<li>CPU<ul>
<li>一个老教授，积分微分无所不能，可以完成十分复杂的任务。</li>
<li>衡量CPU的指标是这个老教授有多厉害！</li>
</ul>
</li>
<li>GPU<ul>
<li>很多很多个小学生，每个小学生只会简单的加减乘除。</li>
<li>衡量GPU的指标是有多少个小学生！</li>
</ul>
</li>
</ul>
<p>若有一项需要运算几亿次加法的任务，你选择哪个？</p>
<h3 id="GPU的应用场景"><a href="#GPU的应用场景" class="headerlink" title="GPU的应用场景"></a>GPU的应用场景</h3><p>什么类型的程序适合在GPU上运行？</p>
<ul>
<li>计算密集型的程序。即大部分运算时间花在寄存器运算上进行的运算。</li>
<li>易于并行的程序。GPU拥有成百上千个核，每一个核在同一时间最好能做同样的事情。</li>
</ul>
<p>破解密码、挖矿、图形渲染、图像处理、深度学习、金融、生物学、……</p>
<h3 id="NVIDIA最新GPU一览"><a href="#NVIDIA最新GPU一览" class="headerlink" title="NVIDIA最新GPU一览"></a>NVIDIA最新GPU一览</h3><table>
<thead>
<tr>
<th>款式</th>
<th>型号</th>
<th>计算能力</th>
<th>单精度性能(TFLOPS)</th>
<th>显存</th>
<th>CUDA Core</th>
</tr>
</thead>
<tbody>
<tr>
<td>高性能计算GPU</td>
<td><a href="http://images.nvidia.com/content/technologies/volta/pdf/437317-Volta-V100-DS-NV-US-WEB.pdf" target="_blank" rel="noopener">Tesla V100</a></td>
<td>7.0</td>
<td>14</td>
<td>16GB</td>
<td>5120</td>
</tr>
<tr>
<td>高性能计算GPU</td>
<td><a href="(http://images.nvidia.com/content/pdf/tesla/cn/Tesla_P100_PCle_%E4%BA%A7%E5%93%81%E5%BD%A9%E9%A1%B5_%E7%BD%91%E7%BB%9C%E7%89%88.PDF">Tesla P100</a>)</td>
<td>6.0</td>
<td>9.3</td>
<td>16GB</td>
<td>3584</td>
</tr>
<tr>
<td>专业制图GPU</td>
<td>Quadro GP100</td>
<td>6.0</td>
<td>10.3</td>
<td>16GB</td>
<td>3584</td>
</tr>
<tr>
<td>专业制图GPU</td>
<td>Quadro P6000</td>
<td>6.1</td>
<td>12</td>
<td>24GB</td>
<td>3840</td>
</tr>
<tr>
<td>桌面GPU GeForce</td>
<td><a href="https://www.nvidia.com/en-us/design-visualization/products/titan-xp/" target="_blank" rel="noopener">NVIDIA TITAN Xp</a></td>
<td>6.1</td>
<td>11</td>
<td>12GB</td>
<td>3584</td>
</tr>
<tr>
<td>桌面GPU GeForce</td>
<td>GTX TITAN X</td>
<td>5.2</td>
<td>7</td>
<td>12GB</td>
<td>3072</td>
</tr>
</tbody>
</table>
<blockquote>
<p>计算能力Compute Capability。与计算速度无关，代表了其硬件层次的规格和可用功能，整数部分为GPU大的架构（1 Tesla 2 Fermi 3 Kepler 5 Maxwell 6 Pascal 7 Volta）。<br>每秒浮点运算次数。1 TFLOPS=每秒1012次浮点运算<br><a href="https://developer.nvidia.com/cuda-gpus#collapse4" target="_blank" rel="noopener">参考</a></p>
</blockquote>
<h2 id="GPU架构"><a href="#GPU架构" class="headerlink" title="GPU架构"></a>GPU架构</h2><h3 id="硬件架构"><a href="#硬件架构" class="headerlink" title="硬件架构"></a><a href="http://www.bijishequ.com/detail/130308" target="_blank" rel="noopener">硬件架构</a></h3><p>SP：最基本的处理单元，streaming processor，也称为CUDA Core。最后具体的指令和任务都是在SP上处理的。GPU进行并行计算，也就是很多个SP同时做处理。</p>
<p>SM：多个SP加上其他的一些资源组成一个streaming multiprocessor。也叫GPU大核，可以看做GPU的心脏（对比CPU核心）。其他资源包括warp scheduler、register、shared memory等。</p>
<p>Tesla P100</p>
<ul>
<li>Tesla P100中包含一块GP100芯片，该芯片中包含60个SM。</li>
<li>1个SM中包含64个SP。</li>
<li>则Tesla P100总的SP个数为<code>60*64=3840</code>，而实际情况，P100只用了56个SM，则SP(CUDA Core)总数为<code>56*64=3584</code>。</li>
<li>软件逻辑上是所有SP是并行的，但是物理上并不是所有SP都能同时执行计算，由于资源问题会导致一些SP会处于挂起、就绪等其他状态，这有关GPU的线程调度。</li>
</ul>
<h3 id="软件架构"><a href="#软件架构" class="headerlink" title="软件架构"></a>软件架构</h3><p><img src="http://outz1n6zr.bkt.clouddn.com/04795d344f33b2a88945624f9428b27e.png" alt="软件架构"></p>
<p>thread：一个CUDA的并行程序会被以许多个threads来执行。</p>
<p>block：若干个threads会被群组成一个block，同一个block中的threads可以同步，也可以通过shared memory通信。可以是一维，二维或者三维。</p>
<p>grid：多个blocks则会再构成grid。可以是一维、二维或者三维。</p>
<p>warp：GPU执行程序时的调度单位，在CUDA架构中, 线程束是指包含32个线程的集合, 这些线程被”编织在一起”, 并且以”步调一致(Lockstep)”的形式执行. 程序的每一行,线程束中的每个线程都将在不同的数据上执行相同的指令.</p>
<h3 id="软硬件架构对应关系"><a href="#软硬件架构对应关系" class="headerlink" title="软硬件架构对应关系"></a>软硬件架构对应关系</h3><p>当一个kernel函数启动后，thread会被分配到SM中执行。</p>
<p>大量的thread可能会被分配到不同的SM，同一个block中的threads必然在同一个SM中并行执行。</p>
<p>每个thread拥有它自己的程序计数器和状态寄存器，并且用该线程自己的数据执行指令。</p>
<p>一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行。</p>
<p>Nvidia把32个threads组成一个warp，warp是调度和运行的基本单元。</p>
<p>warp中所有threads并行的执行相同的指令。一个warp需要占用一个SM运行，多个warps需要轮流进入SM。</p>
<p>由SM的硬件warp scheduler负责调度。目前每个warp包含32个threads。所以，一个GPU上resident thread最多只有 SM*warp个。 </p>
<p><img src="http://outz1n6zr.bkt.clouddn.com/3b73373d63529ff8b36e10ccb8141b00.png" alt="对应关系"></p>
<p>block是软件概念，一个block只会由一个SM调度，程序员在开发时，通过设定block的属性来告诉GPU我需要多少个线程。而具体怎么调度由SM的warps scheduler负责，block一旦被分配好SM，该block就会一直驻留在该SM中，直到执行结束。一个SM可以同时拥有多个blocks，但需要序列执行。</p>
<p>需要注意的是，大部分threads只是逻辑上并行，并不是所有的thread可以在物理上同时执行。例如，遇到分支语句（if else，while，for等）时，各个thread的执行条件不一样必然产生分支执行，这就导致同一个block中的线程可能会有不同步调。另外，并行thread之间的共享数据会导致竞态：多个线程请求同一个数据会导致未定义行为。CUDA提供了同步函数来同步同一个block的thread以保证在进行下一步处理之前，所有thread都到达某个时间点。 </p>
<p>同一个warp中的thread可以以任意顺序执行，active warps被SM资源限制。当一个warp空闲时，SM就可以调度驻留在该SM中另一个可用warp。在并发的warp之间切换是没什么消耗的，因为硬件资源早就被分配到所有thread和block，所以该新调度的warp的状态已经存储在SM中了。不同于CPU，CPU切换线程需要保存/读取线程上下文（register内容），这是非常耗时的，而GPU为每个threads提供物理register，无需保存/读取上下文。 </p>
<h3 id="编程查看GPU的信息"><a href="#编程查看GPU的信息" class="headerlink" title="编程查看GPU的信息"></a>编程查看GPU的信息</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cudaDeviceProp  prop;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">int</span> count;</span><br><span class="line">    cudaGetDeviceCount( &amp;count );</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt; count; i++) &#123;</span><br><span class="line">        cudaGetDeviceProperties( &amp;prop, i );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"   --- Information for device %d ---\n"</span>, i );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Name:  %s\n"</span>, prop.name );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Compute Capability:  %d.%d\n"</span>, prop.major, prop.minor );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"   --- Hardware Information ---\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Total Global Memory:  %ld\n"</span>, prop.totalGlobalMem );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Total Constant Memory:  %ld\n"</span>, prop.totalConstMem );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Streaming Multiprocessor count:  %d\n"</span>,prop.multiProcessorCount);</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Shared Memory per SM:  %ld\n"</span>, prop.sharedMemPerBlock );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Registers per SM:  %d\n"</span>, prop.regsPerBlock );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"   --- Software Information ---\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Threads in Warp:  %d\n"</span>, prop.warpSize );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Max Threads per Block:  %d\n"</span>,prop.maxThreadsPerBlock );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Max Thread Dimensions:  (%d, %d, %d)\n"</span>,prop.maxThreadsDim[<span class="number">0</span>], prop.maxThreadsDim[<span class="number">1</span>], prop.maxThreadsDim[<span class="number">2</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"Max Grid Dimensions:  (%d, %d, %d)\n"</span>,prop.maxGridSize[<span class="number">0</span>], prop.maxGridSize[<span class="number">1</span>], prop.maxGridSize[<span class="number">2</span>] );</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"\n"</span> );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>操作步骤如下：</p>
<ol>
<li>将代码复制到<code>info.cu</code>文件中，或者通过ftp将文件上传。</li>
<li>编译文件 <code>nvcc info.cu</code></li>
<li>若出现错误，请检查语法错误。</li>
<li>运行可执行文件 <code>./a.out</code></li>
</ol>
<p>输出如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">   --- Information for device 0 ---</span><br><span class="line">Name:  Tesla P100-PCIE-16GB</span><br><span class="line">Compute Capability:  6.0</span><br><span class="line">   --- Hardware Information ---</span><br><span class="line">Total Global Memory:  17066885120</span><br><span class="line">Total Constant Memory:  65536</span><br><span class="line">Streaming Multiprocessor count:  56</span><br><span class="line">Shared Memory per SM:  49152</span><br><span class="line">Registers per SM:  65536</span><br><span class="line">   --- Software Information ---</span><br><span class="line">Threads in Warp:  32</span><br><span class="line">Max Threads per Block:  1024</span><br><span class="line">Max Thread Dimensions:  (1024, 1024, 64)</span><br><span class="line">Max Grid Dimensions:  (2147483647, 65535, 65535)</span><br></pre></td></tr></table></figure>
<h2 id="CUDA-C基础"><a href="#CUDA-C基础" class="headerlink" title="CUDA C基础"></a>CUDA C基础</h2><h3 id="CUDA发展史"><a href="#CUDA发展史" class="headerlink" title="CUDA发展史"></a>CUDA发展史</h3><p>2007年以前，通过OpenGL和DirectX的图形API来执行通用计算，难度极大。</p>
<p>2007年NVIDIA推出了CUDA（Computert Unified Device Architecture，统一计算架构）编程环境。</p>
<p>CUDA Toolkit（CUDA SDK）不断升级，从2007年推出的1.0到2017年推出的9.0（latest）。</p>
<h3 id="并发与并行"><a href="#并发与并行" class="headerlink" title="并发与并行"></a>并发与并行</h3><p>并发：并发是一个程序、算法或者问题的可分解属性，它由多个顺序不依赖性或者局部顺序依赖性的结构或单元组成。这就意味着这些单元无论以何种顺序执行或者运算，最终结果都是一样的。</p>
<p>并行：并行(parallelism)是指在具有多个处理单元(如GPU或者多核CPU)的系统上，通过将计算或数据划分为多个部分，将各个部分分配到不同的处理单元上，各处理单元相互协作，同时运行，已达到加快求解速度或提高求解问题规模的目的。</p>
<h3 id="CUDA并行编程模型"><a href="#CUDA并行编程模型" class="headerlink" title="CUDA并行编程模型"></a>CUDA并行编程模型</h3><p><img src="http://outz1n6zr.bkt.clouddn.com/a97718b65efee4716903ba08446b2317.png" alt=""></p>
<ul>
<li>线程级并行（核函数）</li>
<li>CPU+GPU同时工作</li>
<li>内存+显存同时利用</li>
<li>CPU与GPU通信<ul>
<li>存储器复制、映射</li>
</ul>
</li>
<li>串行或部分并行（CPU）+并行（GPU）</li>
</ul>
<p>一个简单的向量加法程序</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//核函数</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">add</span><span class="params">( <span class="keyword">int</span>* dev_a, <span class="keyword">int</span>* dev_b, <span class="keyword">size_t</span> len, <span class="keyword">int</span> *dev_c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; len) dev_c[tid] = dev_a[tid] + dev_b[tid];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//CPU上执行初始化操作</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> len = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">int</span> a[len] ,b[len] , c[len];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++) &#123;</span><br><span class="line">        a[i] = -i;</span><br><span class="line">        b[i] = i * i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//GPU上分配空间</span></span><br><span class="line">    <span class="keyword">int</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line"> </span><br><span class="line">    cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_a, len * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line">    cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_b, len * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line">    cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_c, len * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数据从CPU拷贝至GPU上</span></span><br><span class="line">    cudaMemcpy( dev_a, a, len * <span class="keyword">sizeof</span>(<span class="keyword">int</span>), </span><br><span class="line">                cudaMemcpyHostToDevice );</span><br><span class="line">    cudaMemcpy( dev_b, b, len * <span class="keyword">sizeof</span>(<span class="keyword">int</span>), </span><br><span class="line">                cudaMemcpyHostToDevice );</span><br><span class="line"></span><br><span class="line">    <span class="comment">//执行核函数</span></span><br><span class="line">    add&lt;&lt;&lt;<span class="number">1</span>,len&gt;&gt;&gt;( dev_a, dev_b, len, dev_c );</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//将数据从GPU拷贝至CPU上</span></span><br><span class="line">    cudaMemcpy( c, dev_c, len * <span class="keyword">sizeof</span>(<span class="keyword">int</span>), </span><br><span class="line">                cudaMemcpyDeviceToHost );</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//打印结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d + %d = %d\n"</span>,a[i],b[i],c[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放GPU内存</span></span><br><span class="line">    cudaFree( dev_a );</span><br><span class="line">    cudaFree( dev_b );</span><br><span class="line">    cudaFree( dev_c );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果</p>
<p><img src="http://outz1n6zr.bkt.clouddn.com/6f4edcb49f25d819d49ea0b025bfd3c2.png" alt=""></p>
<h3 id="CUDA-C基础-1"><a href="#CUDA-C基础-1" class="headerlink" title="CUDA C基础"></a>CUDA C基础</h3><p>CUDA C是对C/C++语言进行拓展后形成的变种，兼容C/C++语法，文件类型为“.cu”文件，编译器为“nvcc”，相比传统C/C++，主要添加了以下几个方面：</p>
<ul>
<li>函数类型限定符</li>
<li>执行配置运算符</li>
<li>五个内置变量</li>
<li>变量类型限定符</li>
<li>其他的还有数学函数、原子函数、纹理读取、绑定函数等。</li>
</ul>
<h4 id="函数类型限定符"><a href="#函数类型限定符" class="headerlink" title="函数类型限定符"></a>函数类型限定符</h4><p>用来确定某个函数是在CPU还是GPU上运行，以及这个函数是从CPU调用还是从GPU调用。</p>
<ul>
<li><code>__device__</code> 表示从GPU上调用，在GPU上执行；</li>
<li><code>__global__</code> 表示从CPU上调用，在GPU上执行，也称之为kernel函数；</li>
<li><code>__host__</code> 表示在CPU上调用，在CPU上执行，这也是默认的C函数。</li>
</ul>
<p>若违反调用规则，则编译器会报错。在计算能力3.0及以后的设备中，<code>__global__</code>类型的函数也可以调用<code>__global__</code>类型函数。</p>
<p>正确的调用方式：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">__<span class="function">device__ <span class="keyword">void</span> <span class="title">device_func</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">global_func</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">    device_func();</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, __FILE__);</span><br><span class="line">    global_func&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>错误的调用方式：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">__<span class="function">device__ <span class="keyword">void</span> <span class="title">device_func</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">global_func</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, __FILE__);</span><br><span class="line">    global_func&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    device_func&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>错误信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error: a __device__ function call cannot be configured</span><br></pre></td></tr></table></figure>
<h4 id="执行配置运算符"><a href="#执行配置运算符" class="headerlink" title="执行配置运算符"></a>执行配置运算符</h4><p>执行配置运算符&lt;&lt;&lt; &gt;&gt;&gt;，用来传递内核函数的执行参数。格式如下：</p>
<p><strong>kernel&lt;&lt;<griddim, blockdim,="" memsize,="" stream="">&gt;&gt;(para1, para2, …);</griddim,></strong></p>
<ul>
<li>gridDim 表示网格的大小，可以为1维、2维或者3维。</li>
<li>blockDim 表示块的大小，可以为1维、2维或者3维。</li>
<li>memSize 表示动态分配的共享存储器大小，默认为0。</li>
<li>stream 表示执行的流，默认为0。</li>
<li>para1,para2等为核函数参数。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line">    func&lt;&lt;&lt;<span class="number">128</span>,<span class="number">128</span>&gt;&gt;&gt;(a, b);</span><br><span class="line">    func&lt;&lt;&lt;dim3(<span class="number">128</span>,<span class="number">128</span>),dim3(<span class="number">16</span>,<span class="number">16</span>)&gt;&gt;&gt;(a, b);</span><br><span class="line">    func&lt;&lt;&lt;dim3(<span class="number">128</span>,<span class="number">128</span>,<span class="number">128</span>),dim3(<span class="number">16</span>,<span class="number">16</span>,<span class="number">2</span>)&gt;&gt;&gt;(a, b);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="五个内置变量"><a href="#五个内置变量" class="headerlink" title="五个内置变量"></a>五个内置变量</h4><p>这些内置变量用来在运行时获得Grid和Block的尺寸及线程索引等信息。</p>
<ul>
<li><code>gridDim</code>：包含三个元素x,y,z的结构体，表示Grid在三个方向上的尺寸，对应于执行配置中的第一个参数。</li>
<li><code>blockDim</code>：包含三个元素x,y,z的结构体，表示Block在三个方向上的尺寸，对应于执行配置中的第二个参数。</li>
<li><code>blockIdx</code>：包含三个元素x,y,z的结构体，分别表示当前线程所在块在网格中x,y,z方向上的索引</li>
<li><code>threadIdx</code>：包含三个元素x,y,z的结构体，分别表示当前线程在其所在块中x,y,z方向上的索引。</li>
<li><code>warpSize</code>：表明warp的尺寸。</li>
</ul>
<p>一维结构中，利用内置变量来确定线程Idx：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br></pre></td></tr></table></figure>
<p><img src="http://outz1n6zr.bkt.clouddn.com/4271bf457dd3942214ababb5020046bf.png" alt=""></p>
<p>二维结构中，利用内置变量来确定线程Idx：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//左边有x个线程</span></span><br><span class="line"><span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"><span class="comment">//上方有y个线程</span></span><br><span class="line"><span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y; </span><br><span class="line"><span class="comment">//实际线程Idx</span></span><br><span class="line"><span class="keyword">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br></pre></td></tr></table></figure>
<p><img src="http://outz1n6zr.bkt.clouddn.com/04795d344f33b2a88945624f9428b27e.png" alt=""></p>
<h4 id="变量类型限定符"><a href="#变量类型限定符" class="headerlink" title="变量类型限定符"></a>变量类型限定符</h4><p>用来确定某个变量在设备上的内存位置。</p>
<ul>
<li><code>__device__</code> 表示位于全局内存空间，默认类型；</li>
<li><code>__shared__</code> 表示位于共享内存空间；</li>
<li><code>__constant__</code> 表示位于常量内存空间；</li>
<li><code>texture</code> 表示其绑定的变量可以被纹理缓存加速访问。</li>
</ul>
<p><code>__device__</code> 类型变量的申请、赋值与释放：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_a, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line">cudaMemcpy( dev_a, a, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>), cudaMemcpyHostToDevice );</span><br><span class="line">cudaMemcpy( c, dev_c, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>), cudaMemcpyDeviceToHost );</span><br><span class="line">cudaFree( dev_a );</span><br></pre></td></tr></table></figure>
<p>全部程序参照上文的“一个简单的向量加法程序”节。</p>
<p>将“<code>__share__</code>”添加到变量声明中，对于GPU中的每个线程块，CUDA C编译器都创建该变量的一个副本。同一线程块中的线程共享这块内存，不同线程块之间内存不可见。而且，共享内存缓冲区驻留在物理GPU上，而不是驻留在GPU之外的系统内存中。因此，在访问共享内存时的延迟要远远低于访问普通缓冲区的延迟，使得共享内存变得十分高效。</p>
<p>CUDA还提供了函数“<code>__syncthreads()</code>”来进行线程同步。</p>
<p>将“<code>__constant__</code>”添加到变量声明中，则该变量位于常量内存，常量内存中的数据为只读权限。相比于全局内存，常量内存具有以下优点：</p>
<ul>
<li>对常量内存的单次读操作，可以广播到其他的邻近线程（线程束中一半的线程），这将节约15次读取操作。</li>
<li>常量内存的数据将缓存起来，因此对相同地址的连续读操作将不会产生额外的内存通信量。</li>
</ul>
<p>全局内存</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">People *dev_peoples;</span><br><span class="line">cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_peoples, N*<span class="keyword">sizeof</span>(People) );</span><br><span class="line">cudaMemcpy( dev_peoples, peoples, N*<span class="keyword">sizeof</span>(People), cudaMemcpyHostToDevice);</span><br></pre></td></tr></table></figure>
<p>常量内存</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__constant__ People dev_peoples[N]; <span class="comment">//全局变量</span></span><br><span class="line"> </span><br><span class="line">cudaMemcpyToSymbol( dev_peoples, peoples, N * <span class="keyword">sizeof</span>(People) );</span><br></pre></td></tr></table></figure>
<p>将“texture”绑定到某全局变量上，则在读取该变量时，GPU将缓存该块内存附近的数据，并分享到线程束中的其他线程。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建纹理内存引用, 必须为全局变量</span></span><br><span class="line">texture&lt;<span class="keyword">float</span>&gt;  texValue;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 初始化函数中 */</span></span><br><span class="line"><span class="comment">// 首先在GPU上分配内存</span></span><br><span class="line"><span class="keyword">float</span> *dev_value;</span><br><span class="line">cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_value, size );</span><br><span class="line"><span class="comment">// 告诉GPU我们希望将指定的缓冲区作为纹理来使用</span></span><br><span class="line"><span class="comment">// 我们希望将纹理引用作为纹理的"名字"</span></span><br><span class="line"><span class="comment">// 当读取内存时, 用纹理引用texValue, 当要写内存时, 需用全局变量dev_value</span></span><br><span class="line">cudaBindTexture( <span class="literal">NULL</span>, texValue, dev_value, size );</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 核函数中 */</span></span><br><span class="line"><span class="comment">// 核函数中读取方式不再是[]读取, 而要调用函数</span></span><br><span class="line"><span class="keyword">float</span> c = tex1Dfetch(texValue, offset)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 释放函数</span></span><br><span class="line">cudaUnbindTexture( texValue );</span><br><span class="line">cudaFree( dev_value );</span><br></pre></td></tr></table></figure>
<h4 id="共享内存与线程同步"><a href="#共享内存与线程同步" class="headerlink" title="共享内存与线程同步"></a>共享内存与线程同步</h4><p>上文我们实现了向量加法，这里我们将介绍新的运算——向量的点积。</p>
<p>假设向量大小为N，按照上文的方法，我们将申请大小为N的空间，用来存放向量元素互乘的结果，然后在CPU上对N个乘积进行累加。</p>
<p>若我们需要在GPU上进行累加操作呢？</p>
<p>受限于GPU线程块中线程个数的上限问题，若向量尺寸过大，则需分配到多个线程块中。</p>
<p>我们计划在每个线程块中计算各自的点积结果，并返回线程块个数个点积结果，并在CPU上进行累加。</p>
<p>代码如下。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">100000</span>; <span class="comment">//向量维度</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> threadsPerBlock = <span class="number">256</span>; <span class="comment">//每个线程块中的线程数</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> blocksNum = (N + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock; <span class="comment">//线程块个数</span></span><br><span class="line"> </span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">dot</span><span class="params">( <span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">float</span> *c )</span> </span>&#123;</span><br><span class="line">    <span class="comment">//共享变量声明</span></span><br><span class="line">    __shared__ <span class="keyword">float</span> cache[threadsPerBlock]; </span><br><span class="line"> </span><br><span class="line">    <span class="comment">//根据内置变量定位当前线程Idx</span></span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> cacheIndex = threadIdx.x;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//向量乘法运算</span></span><br><span class="line">    <span class="keyword">if</span> (tid &lt; N) cache[cacheIndex] = a[tid] * b[tid];</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//同步块内线程</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将块内的乘积进行累加</span></span><br><span class="line">    <span class="keyword">int</span> i = blockDim.x/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span> (i != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cacheIndex &lt; i)</span><br><span class="line">            cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">        __syncthreads();</span><br><span class="line">        i /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (cacheIndex == <span class="number">0</span>)</span><br><span class="line">        c[blockIdx.x] = cache[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//初始化原始数据</span></span><br><span class="line">    <span class="keyword">float</span>   *a, *b, c, *partial_c;</span><br><span class="line">    a = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>( N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>) );</span><br><span class="line">    b = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>( N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>) );</span><br><span class="line">    partial_c = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>( blocksNum*<span class="keyword">sizeof</span>(<span class="keyword">float</span>) );</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i*<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//分配GPU空间</span></span><br><span class="line">    <span class="keyword">float</span>   *dev_a, *dev_b, *dev_partial_c;</span><br><span class="line">    cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_a, N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>) );</span><br><span class="line">    cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_b, N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>) );</span><br><span class="line">    cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_partial_c, </span><br><span class="line">                blocksNum*<span class="keyword">sizeof</span>(<span class="keyword">float</span>) );</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//将数据从CPU复制到GPU</span></span><br><span class="line">    cudaMemcpy( dev_a, a, N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>), </span><br><span class="line">                cudaMemcpyHostToDevice );</span><br><span class="line">    cudaMemcpy( dev_b, b, N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>), </span><br><span class="line">                cudaMemcpyHostToDevice );</span><br><span class="line"></span><br><span class="line">    <span class="comment">//核函数执行</span></span><br><span class="line">    dot&lt;&lt;&lt;blocksNum,threadsPerBlock&gt;&gt;&gt;(</span><br><span class="line">        dev_a, dev_b, dev_partial_c );</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//将结果中GPU复制到CPU</span></span><br><span class="line">    cudaMemcpy( partial_c, dev_partial_c,</span><br><span class="line">                blocksNum*<span class="keyword">sizeof</span>(<span class="keyword">float</span>),</span><br><span class="line">                cudaMemcpyDeviceToHost );</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//在CPU中计算最后的结果</span></span><br><span class="line">    c = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;blocksNum; i++) &#123;</span><br><span class="line">        c += partial_c[i];</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//比较结果是否正确</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">define</span> sum_squares(x)  (x*(x+1)*(2*x+1)/6)</span></span><br><span class="line">    <span class="built_in">printf</span>( <span class="string">"Does GPU value %g = %g?\n"</span>, c,</span><br><span class="line">             <span class="number">2</span> * sum_squares( (<span class="keyword">float</span>)(N - <span class="number">1</span>) ) );</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//释放内存和显存</span></span><br><span class="line">    cudaFree( dev_a );</span><br><span class="line">    cudaFree( dev_b );</span><br><span class="line">    cudaFree( dev_partial_c );</span><br><span class="line">    <span class="built_in">free</span>( a );</span><br><span class="line">    <span class="built_in">free</span>( b );</span><br><span class="line">    <span class="built_in">free</span>( partial_c );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="函数调用检查"><a href="#函数调用检查" class="headerlink" title="函数调用检查"></a>函数调用检查</h3><p>检查CUDA API调用是否正常</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">HandleError</span><span class="params">( cudaError_t err,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">const</span> <span class="keyword">char</span> *file,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">int</span> line )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"%s in %s at line %d\n"</span>, cudaGetErrorString( err ),</span><br><span class="line">                file, line );</span><br><span class="line">        <span class="built_in">exit</span>( EXIT_FAILURE );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))</span></span><br></pre></td></tr></table></figure>
<h3 id="性能测量"><a href="#性能测量" class="headerlink" title="性能测量"></a>性能测量</h3><p>如何评判我的GPU程序运行快慢？</p>
<p>CUDA提供使用事件来在GPU上记录时间戳。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t     start, stop;</span><br><span class="line">cudaEventCreate( &amp;start );</span><br><span class="line">cudaEventCreate( &amp;stop );</span><br><span class="line">cudaEventRecord( start, <span class="number">0</span> );</span><br><span class="line"> </span><br><span class="line"><span class="comment">//在GPU上执行一些工作</span></span><br><span class="line"> </span><br><span class="line">cudaEventRecord( stop, <span class="number">0</span> );</span><br><span class="line">cudaEventSynchronize( stop );</span><br><span class="line"><span class="keyword">float</span>   elapsedTime;</span><br><span class="line">cudaEventElapsedTime( &amp;elapsedTime, start, stop );</span><br><span class="line"><span class="built_in">printf</span>( <span class="string">"时间花费为:  %3.1f ms\n"</span>, elapsedTime );</span><br><span class="line"> </span><br><span class="line">cudaEventDestroy( start );</span><br><span class="line">cudaEventDestroy( stop );</span><br></pre></td></tr></table></figure>
<h3 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h3><p>代码见<a href="https://github.com/liqiang311/oj/tree/master/media" target="_blank" rel="noopener">Github</a></p>
<h3 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h3><p><a href="http://heisetoufa.iteye.com/blog/227687" target="_blank" rel="noopener">尽量祛除if-else</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/cuda/" rel="tag"># cuda</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/10/19/gopl/" rel="next" title="《Go语言圣经》读书笔记">
                <i class="fa fa-chevron-left"></i> 《Go语言圣经》读书笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/10/25/git/" rel="prev" title="Git相关">
                Git相关 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">linyemin</p>
              <p class="site-description motion-element" itemprop="description">海阔凭鱼跃，天高任鸟飞</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">69</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">45</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#资料"><span class="nav-number">1.</span> <span class="nav-text">资料</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU与GPU"><span class="nav-number">2.</span> <span class="nav-text">CPU与GPU</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU的设计理念——低延时"><span class="nav-number">2.1.</span> <span class="nav-text">CPU的设计理念——低延时</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU的设计理念——大吞吐量"><span class="nav-number">2.2.</span> <span class="nav-text">GPU的设计理念——大吞吐量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#形象的比喻"><span class="nav-number">2.3.</span> <span class="nav-text">形象的比喻</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU的应用场景"><span class="nav-number">2.4.</span> <span class="nav-text">GPU的应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NVIDIA最新GPU一览"><span class="nav-number">2.5.</span> <span class="nav-text">NVIDIA最新GPU一览</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPU架构"><span class="nav-number">3.</span> <span class="nav-text">GPU架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#硬件架构"><span class="nav-number">3.1.</span> <span class="nav-text">硬件架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#软件架构"><span class="nav-number">3.2.</span> <span class="nav-text">软件架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#软硬件架构对应关系"><span class="nav-number">3.3.</span> <span class="nav-text">软硬件架构对应关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编程查看GPU的信息"><span class="nav-number">3.4.</span> <span class="nav-text">编程查看GPU的信息</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-C基础"><span class="nav-number">4.</span> <span class="nav-text">CUDA C基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA发展史"><span class="nav-number">4.1.</span> <span class="nav-text">CUDA发展史</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#并发与并行"><span class="nav-number">4.2.</span> <span class="nav-text">并发与并行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA并行编程模型"><span class="nav-number">4.3.</span> <span class="nav-text">CUDA并行编程模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA-C基础-1"><span class="nav-number">4.4.</span> <span class="nav-text">CUDA C基础</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#函数类型限定符"><span class="nav-number">4.4.1.</span> <span class="nav-text">函数类型限定符</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#执行配置运算符"><span class="nav-number">4.4.2.</span> <span class="nav-text">执行配置运算符</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#五个内置变量"><span class="nav-number">4.4.3.</span> <span class="nav-text">五个内置变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#变量类型限定符"><span class="nav-number">4.4.4.</span> <span class="nav-text">变量类型限定符</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#共享内存与线程同步"><span class="nav-number">4.4.5.</span> <span class="nav-text">共享内存与线程同步</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实战"><span class="nav-number">5.</span> <span class="nav-text">实战</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#函数调用检查"><span class="nav-number">5.1.</span> <span class="nav-text">函数调用检查</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#性能测量"><span class="nav-number">5.2.</span> <span class="nav-text">性能测量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中位数"><span class="nav-number">5.3.</span> <span class="nav-text">中位数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代码优化"><span class="nav-number">5.4.</span> <span class="nav-text">代码优化</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">linyemin</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
